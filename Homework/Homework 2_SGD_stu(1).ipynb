{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2: Wine Quality Prediction Using SGD\n",
    "### Course: CS 474/574: Deep Learning/2021 Fall\n",
    "### Due: 10/01/2021\n",
    "\n",
    "\n",
    "Add your code to the following sections:\n",
    "\n",
    "    ## add your code here\n",
    "    #-----------------------\n",
    "\n",
    "    #---------------------------------\n",
    "    \n",
    "Description: In this homework, you are going to practice cross-validation and implement the stochastic gradient optimization (mini-batch) to solve the wine quality prediction problem. Using the following code as your template. Specific requirements:\n",
    "\n",
    "1. Use all function definitions given in the code (e.g., def SGD(X, Y, lr = 0.001, batch_size = 32, epoch = 100):); and do not change the function names and input arguments. (deduct 5 points for doing this)\n",
    "\n",
    "2. Evaluate (Cross-validation) the model trained using GD (20 points)\n",
    "\n",
    "3. SGD implementation. 40 pts\n",
    "   \n",
    "4. Calculate and print out the MSE and MAE values of SGD for the training and test sets (15 points)\n",
    "5. Plot the loss curve of the SGD. (5 points)\n",
    "6. Plot the mse curves on the training and test sets using different models (w_hist). (20 points)\n",
    "\n",
    "### Common mistakes\n",
    "    \n",
    "1. Call GD and SGD using the whole dataset\n",
    "\n",
    "    -- GD and SGD are used to optimize the model (learn w); and we should call them using the training sets\n",
    "   \n",
    "2. Calculate gradient using the whole training set for SGD\n",
    "    \n",
    "    -- In SGD, update gradient only using mini-batches\n",
    "  \n",
    "3. Calculate the loss of each epoch using the average of all minibatches\n",
    "    \n",
    "    -- should use the w of the last mini-batch and the whole training set to calculate the loss  \n",
    "   \n",
    "4. Mix concepts of loss function and evaulation metrics\n",
    "    -- loss function: for optimization purpose (gradient). We use the sum of square errors in this homework. L = 1/2 * sum(y_hat_i - y_i)^2\n",
    "    \n",
    "    -- evaluation metrics: mse and mae: mse = 1/m * sum(y_hat_i - y_i)^2, mae = 1/m * sum(abs(y_hat_i - y_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data, implement the model, loss function and GD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: X: (4898, 11) Y: (4898,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## (1) Data preparation\n",
    "df=pd.read_csv('winequality-white.csv', sep = ';')\n",
    "df\n",
    "X = df.values[:, :11]\n",
    "Y = df.values[:, 11]\n",
    "print('Data shape:', 'X:', X.shape, 'Y:', Y.shape)\n",
    "\n",
    "# data normalization\n",
    "min_vals = np.min(X, axis = 0)\n",
    "max_vals = np.max(X, axis = 0)\n",
    "X1 = (X-min_vals)/(max_vals-min_vals)\n",
    "\n",
    "##(2) Assume a linear mode that y = w0*1 + w_1*x_1 +w_2*x_2+...+ w_11*x_11\n",
    "def predict(X, w):\n",
    "    '''\n",
    "    X: input feature vectors:m*n\n",
    "    w: weights\n",
    "    \n",
    "    return Y_hat\n",
    "    '''\n",
    "    # Prediction\n",
    "    Y_hat = np.zeros((X.shape[0]))\n",
    "    for idx, x in enumerate(X):          \n",
    "        y_hat = w[0] + np.dot(w[1:].T, np.c_[x]) # linear model\n",
    "        Y_hat[idx] = y_hat    \n",
    "    return Y_hat\n",
    "\n",
    "## (3) Loss function: L = 1/2 * sum(y_hat_i - y_i)^2\n",
    "def loss(w, X, Y):\n",
    "    '''\n",
    "    w: weights\n",
    "    X: input feature vectors\n",
    "    Y: targets\n",
    "    '''\n",
    "    Y_hat = predict(X, w)\n",
    "    loss = 1/2* np.sum(np.square(Y - Y_hat))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Optimization 1: Gradient Descent\n",
    "def GD(X, Y, lr = 0.001, delta = 0.01, max_iter = 100):\n",
    "    '''\n",
    "    X: training data\n",
    "    Y: training target\n",
    "    lr: learning rate\n",
    "    max_iter: the max iterations\n",
    "    '''\n",
    "    \n",
    "    m = len(Y)\n",
    "    b = np.reshape(Y, [Y.shape[0],1])\n",
    "    w = np.random.rand(X.shape[1] + 1, 1)\n",
    "    A = np.c_[np.ones((m, 1)), X]\n",
    "    gradient = A.T.dot(np.dot(A, w)-b)\n",
    "    \n",
    "    loss_hist = np.zeros(max_iter) # history of loss\n",
    "    w_hist = np.zeros((max_iter, w.shape[0])) # history of weight\n",
    "    loss_w = 0\n",
    "    i = 0                  \n",
    "    while(np.linalg.norm(gradient) > delta) and (i < max_iter):\n",
    "        w_hist[i,:] = w.T\n",
    "        loss_w = loss(w, X, Y)\n",
    "        print(i, 'loss:', loss_w)\n",
    "        loss_hist[i] = loss_w\n",
    "        \n",
    "        w = w - lr*gradient        \n",
    "        gradient = A.T.dot(np.dot(A, w)-b) # update the gradient using new w\n",
    "        i = i + 1\n",
    "        \n",
    "    w_star = w  \n",
    "    return w_star, loss_hist, w_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model evaluation using cross-validation (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3428, 11) (1470, 11)\n"
     ]
    }
   ],
   "source": [
    "## 2.1 Split the dataset into training (70%) and test (30%) sets. (5 points)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## add your code here\n",
    "#-----------------------\n",
    "X_train, X_test, y_train, y_test =train_test_split(X1,Y, test_size = 0.30)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "#---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 31680.13274413908\n",
      "1 loss: 6236.226395514606\n",
      "2 loss: 2192.9999370022088\n",
      "3 loss: 1545.2063471210167\n",
      "4 loss: 1436.2729398544618\n",
      "5 loss: 1412.9938016090173\n",
      "6 loss: 1403.4619852219093\n",
      "7 loss: 1396.2645199306874\n",
      "8 loss: 1389.5860717110743\n",
      "9 loss: 1383.1341354082742\n",
      "10 loss: 1376.857946211092\n",
      "11 loss: 1370.7452280400476\n",
      "12 loss: 1364.7899429953088\n",
      "13 loss: 1358.987170590363\n",
      "14 loss: 1353.3322913100587\n",
      "15 loss: 1347.8208531850962\n",
      "16 loss: 1342.4485468514104\n",
      "17 loss: 1337.2111979400145\n",
      "18 loss: 1332.1047623317108\n",
      "19 loss: 1327.1253219780272\n",
      "20 loss: 1322.2690809201645\n",
      "21 loss: 1317.5323614441197\n",
      "22 loss: 1312.911600358862\n",
      "23 loss: 1308.4033453922707\n",
      "24 loss: 1304.0042517008987\n",
      "25 loss: 1299.7110784899205\n",
      "26 loss: 1295.5206857397811\n",
      "27 loss: 1291.4300310361737\n",
      "28 loss: 1287.4361665000774\n",
      "29 loss: 1283.5362358146956\n",
      "30 loss: 1279.72747134623\n",
      "31 loss: 1276.0071913555266\n",
      "32 loss: 1272.3727972977233\n",
      "33 loss: 1268.8217712071132\n",
      "34 loss: 1265.3516731645382\n",
      "35 loss: 1261.9601388446963\n",
      "36 loss: 1258.6448771408463\n",
      "37 loss: 1255.4036678644566\n",
      "38 loss: 1252.234359517433\n",
      "39 loss: 1249.1348671346364\n",
      "40 loss: 1246.1031701944598\n",
      "41 loss: 1243.137310595325\n",
      "42 loss: 1240.2353906960063\n",
      "43 loss: 1237.3955714177728\n",
      "44 loss: 1234.6160704063905\n",
      "45 loss: 1231.8951602520965\n",
      "46 loss: 1229.2311667657111\n",
      "47 loss: 1226.6224673091158\n",
      "48 loss: 1224.0674891783804\n",
      "49 loss: 1221.5647080378735\n",
      "50 loss: 1219.112646403748\n",
      "51 loss: 1216.70987217524\n",
      "52 loss: 1214.354997212275\n",
      "53 loss: 1212.0466759579103\n",
      "54 loss: 1209.7836041042062\n",
      "55 loss: 1207.56451730015\n",
      "56 loss: 1205.388189900304\n",
      "57 loss: 1203.2534337528919\n",
      "58 loss: 1201.159097026079\n",
      "59 loss: 1199.1040630712407\n",
      "60 loss: 1197.0872493220454\n",
      "61 loss: 1195.1076062282282\n",
      "62 loss: 1193.164116222957\n",
      "63 loss: 1191.2557927227267\n",
      "64 loss: 1189.3816791587585\n",
      "65 loss: 1187.5408480389103\n",
      "66 loss: 1185.7324000391282\n",
      "67 loss: 1183.9554631235162\n",
      "68 loss: 1182.2091916921092\n",
      "69 loss: 1180.4927657554845\n",
      "70 loss: 1178.8053901353596\n",
      "71 loss: 1177.146293690354\n",
      "72 loss: 1175.5147285661265\n",
      "73 loss: 1173.9099694691129\n",
      "74 loss: 1172.331312963122\n",
      "75 loss: 1170.7780767880672\n",
      "76 loss: 1169.249599200135\n",
      "77 loss: 1167.7452383327145\n",
      "78 loss: 1166.2643715774332\n",
      "79 loss: 1164.8063949846596\n",
      "80 loss: 1163.3707226828678\n",
      "81 loss: 1161.956786316257\n",
      "82 loss: 1160.5640345000593\n",
      "83 loss: 1159.1919322929741\n",
      "84 loss: 1157.8399606861872\n",
      "85 loss: 1156.5076161084526\n",
      "86 loss: 1155.1944099467323\n",
      "87 loss: 1153.899868081899\n",
      "88 loss: 1152.6235304390295\n",
      "89 loss: 1151.3649505518274\n",
      "90 loss: 1150.123695140729\n",
      "91 loss: 1148.8993437042639\n",
      "92 loss: 1147.6914881232456\n",
      "93 loss: 1146.4997322773938\n",
      "94 loss: 1145.3236916739943\n",
      "95 loss: 1144.1629930882139\n",
      "96 loss: 1143.0172742147083\n",
      "97 loss: 1141.8861833301617\n",
      "98 loss: 1140.7693789664163\n",
      "99 loss: 1139.6665295938556\n",
      "[[0.52484455 0.52367377 0.38112462 ... 0.33375431 0.79964498 0.06926777]\n",
      " [1.96465144 0.94106185 0.65411453 ... 0.95153981 1.24606286 0.68104762]\n",
      " [2.53982324 1.10528401 0.75804444 ... 1.19604092 1.4191102  0.93739463]\n",
      " ...\n",
      " [3.24617023 0.98312443 0.17224355 ... 1.13252694 1.01132148 2.11470629]\n",
      " [3.24981254 0.98116831 0.16622984 ... 1.13044636 1.00750641 2.11912836]\n",
      " [3.25345274 0.97921683 0.16023342 ... 1.12837284 1.00371733 2.12347695]]\n"
     ]
    }
   ],
   "source": [
    "## 2.2 Model training using the training set and the GD function (5 points )\n",
    "## add your code here\n",
    "#-----------------------\n",
    "w_star, loss_hist, w_hist = GD(X_train,y_train, lr=0.0001)\n",
    "print(w_hist)\n",
    "#---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mse: 0.6642808129024048 and training mae :0.6313308898582243\n",
      "test mse: 0.6890142836796471 and test mae: 0.6472715223174836\n"
     ]
    }
   ],
   "source": [
    "## 2.3. calculating mse&mae values on the training set and test set, respectively. (10 points)\n",
    "\n",
    "#training error\n",
    "## add your code here\n",
    "#-----------------------\n",
    "y_train_hat = predict(X_train, w_star)\n",
    "mse_train = (np.sum(np.square(y_train_hat-y_train)))/(X_train.shape[0])\n",
    "mae_train = (np.sum(np.absolute(y_train_hat-y_train)))/(X_train.shape[0])\n",
    "print('training mse: {} and training mae :{}'.format(mse_train, mae_train))\n",
    "#---------------------------------\n",
    "\n",
    "\n",
    "## test error\n",
    "## add your code here\n",
    "#-----------------------\n",
    "y_test_hat = predict(X_test, w_star)\n",
    "mse_test = (np.sum(np.square(y_test_hat-y_test)))/(X_test.shape[0])\n",
    "mae_test = (np.sum(np.absolute(y_test_hat-y_test)))/(X_test.shape[0])\n",
    "print('test mse: {} and test mae: {}'.format(mse_test, mae_test))\n",
    "#---------------------------------\n",
    "#training mse: 0.7867769198855628 and training mae:0.6927334108062077\n",
    "#test mse: 0.8391500534666578 and test mae:0.714897056700805"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SGD implementation (40 points)\n",
    "Use the SGD function definition given in the code (def SGD(X, Y, lr = 0.001, batch_size = 32, epoch = 100):); and do not change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def SGD(X, Y, lr = 0.001, batch_size = 32, epoch = 100): \n",
    "    '''Implement the minibatch Gradient Desent approach\n",
    "    \n",
    "        X: training data\n",
    "        Y: training target\n",
    "        lr: learning rate\n",
    "        batch_size: batch size\n",
    "        epoch: number of max epoches\n",
    "        \n",
    "        return: w_star, w_hist, loss_hist\n",
    "    '''\n",
    "    m = len(Y)\n",
    "    np.random.seed(9)\n",
    "    w = np.random.rand(X.shape[1]+1, 1)    #(12,1) values in [0, 1)\n",
    "    w_hist = np.zeros((epoch, w.shape[0])) # (epoch,12) \n",
    "    loss_hist = np.zeros(epoch)            # (epoch,)\n",
    "   \n",
    "    \n",
    "    ## add your code here\n",
    "    #-----------------------\n",
    "    for i in range(epoch):\n",
    "        #(1) Shuffle data (X and Y) at the beginning of each epoch. (5 points)\n",
    "        X_shuff, Y_shuff = shuffle(X,Y)\n",
    "        #(2) go through all minibatches and update w. (30 points)\n",
    "        for b in range(int(m/batch_size)): \n",
    "            # prepare the b mininath X_batch and Y_batch. 10 points\n",
    "            X_batch = X_shuff[b*batch_size:(b+1)*batch_size]\n",
    "            Y_batch = Y_shuff[b*batch_size:(b+1)*batch_size]\n",
    "            #prepare A_batch and b_batch. 10 points\n",
    "            A_batch = np.c_[np.ones((batch_size, 1)), X_batch]\n",
    "            b_batch = np.reshape(Y_batch, [Y_batch.shape[0],1])\n",
    "            #gradient calcualation and w update. 10 points\n",
    "            gradient = A_batch.T.dot(np.dot(A_batch, w)-b_batch)\n",
    "            w = w - lr*gradient\n",
    "            #print(i, b, X_batch.shape, A_batch.shape)\n",
    "\n",
    "            \n",
    "            \n",
    "        ## (3) Save the loss and current weight for each epoch. 5 points\n",
    "        loss_hist[i] = loss(w, X_shuff, Y_shuff)\n",
    "        w_hist[i,:] = w.T\n",
    "        \n",
    "        print(i, loss_hist[i])\n",
    "        \n",
    "        ##(4) Decay learning rate at the end of each epoch. \n",
    "        lr = lr * 0.9\n",
    "    #---------------------------------\n",
    "    \n",
    "    w_star = w\n",
    "    return w_star, w_hist, loss_hist  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate and print out the MSE and MAE values of SGD for the training and test sets (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13434.286587114446\n",
      "1 5383.011916986167\n",
      "2 2820.361921850462\n",
      "3 1912.9109116720188\n",
      "4 1559.0159380833134\n",
      "5 1409.1655864543427\n",
      "6 1340.1681447982664\n",
      "7 1306.3300546547862\n",
      "8 1288.0186953593143\n",
      "9 1277.7264697812616\n",
      "10 1271.410512421924\n",
      "11 1267.3433052328596\n",
      "12 1264.7261336351198\n",
      "13 1262.8376347370486\n",
      "14 1261.4720038912901\n",
      "15 1260.4362289431706\n",
      "16 1259.5983476331887\n",
      "17 1258.9362605659196\n",
      "18 1258.3793620267043\n",
      "19 1257.9221374149877\n",
      "20 1257.5308235687207\n",
      "21 1257.202954229621\n",
      "22 1256.9111102724842\n",
      "23 1256.6589824589746\n",
      "24 1256.4373687132636\n",
      "25 1256.2449605808529\n",
      "26 1256.074875817415\n",
      "27 1255.923654554331\n",
      "28 1255.7894946866518\n",
      "29 1255.6714702657414\n",
      "30 1255.566816261577\n",
      "31 1255.4723413467798\n",
      "32 1255.3881219765954\n",
      "33 1255.3133620265821\n",
      "34 1255.2462054301145\n",
      "35 1255.1862398122125\n",
      "36 1255.1319937544035\n",
      "37 1255.0839252172602\n",
      "38 1255.0404388129366\n",
      "39 1255.0023537468346\n",
      "40 1254.967636835304\n",
      "41 1254.93639877518\n",
      "42 1254.9081202779416\n",
      "43 1254.8828690383257\n",
      "44 1254.8602800577198\n",
      "45 1254.8398034120341\n",
      "46 1254.8215581589084\n",
      "47 1254.8049638299171\n",
      "48 1254.790264475902\n",
      "49 1254.7769846702972\n",
      "Predicted: 6.044466274052485    True: 6.0\n",
      "Predicted: 5.561004243609437    True: 6.0\n",
      "Predicted: 5.829736721743592    True: 6.0\n",
      "Predicted: 6.074589494941467    True: 6.0\n",
      "Predicted: 5.801757385587896    True: 6.0\n",
      "Predicted: 5.468416903900261    True: 5.0\n",
      "Predicted: 6.2925592586598995    True: 7.0\n",
      "Predicted: 5.528479444272207    True: 6.0\n",
      "Predicted: 6.433281616694257    True: 7.0\n",
      "Predicted: 5.299972250334691    True: 6.0\n",
      "training mse: 0.7320752535999401 and training mae :0.6626437211283829\n",
      "test mse: 0.7499757092044739 and test mae: 0.6769322839419656\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 50\n",
    "\n",
    "#train model using SGD\n",
    "w_star_SGD, w_hist_SGD, loss_hist_SGD = SGD(X_train, y_train, lr = 0.0001, batch_size = batch_size, epoch = n_epochs)\n",
    "\n",
    "## add your code here\n",
    "#------------------------------------------------------------\n",
    "#(1) print out the predicted wine quality values and the true quality \n",
    "# values of the first 10 data samples in the test dataset.  5 points\n",
    "\n",
    "Y_train_hat = predict(X_train, w_star_SGD)\n",
    "Y_test_hat = predict(X_test, w_star_SGD)\n",
    "\n",
    "for i in range(10):\n",
    "    print('Predicted: {}    True: {}'.format(Y_test_hat[i], y_test[i]))\n",
    "\n",
    "#(2) mse and mae of the training set. 5 points\n",
    "mse_train = (np.sum(np.square(Y_train_hat-y_train)))/(X_train.shape[0])\n",
    "mae_train = (np.sum(np.absolute(Y_train_hat-y_train)))/(X_train.shape[0])\n",
    "print('training mse: {} and training mae :{}'.format(mse_train, mae_train))\n",
    "\n",
    "\n",
    "#(3)mse and mae of the test set. 5 points\n",
    "mse_test = (np.sum(np.square(Y_test_hat-y_test)))/(X_test.shape[0])\n",
    "mae_test = (np.sum(np.absolute(Y_test_hat-y_test)))/(X_test.shape[0])\n",
    "print('test mse: {} and test mae: {}'.format(mse_test, mae_test))\n",
    "#-------------------------------------------------------------------\n",
    "#Predicted: [6.  5.6 5.7 6.5 5.7 7.  6.7 6.2 5.7 5.8]\n",
    "#True [5. 6. 7. 8. 5. 4. 6. 5. 7. 5.]\n",
    "#training mse: 0.7218402431182253 and training mae:0.6595991336722727\n",
    "#test mse: 0.7735707034736699 and test mae:0.6839863502607874"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Plot the loss curve of the SGD. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add your code here\n",
    "#-----------------------\n",
    "plt.plot(range(1,n_epochs+1), loss_hist[:n_epochs], label=\"loss\") # loss history is broken some how. didnt have time to fix\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plot the mse curves on the training and test sets using different models (w_hist). (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse_SGD_train=np.zeros(n_epochs)\n",
    "mse_SGD_test=np.zeros(n_epochs)\n",
    "\n",
    "## add your code here\n",
    "#-----------------------\n",
    "for i in range(n_epochs):                           #find mse_train and mse_test for each model\n",
    "    Y_train_hat = predict(X_train, w_hist_SGD[i])\n",
    "    Y_test_hat = predict(X_test, w_hist_SGD[i])\n",
    "    mse_SGD_train[i] = (np.sum(np.square(Y_train_hat-y_train)))/(X_train.shape[0])\n",
    "    mse_SGD_test[i] = (np.sum(np.square(Y_test_hat-y_test)))/(X_test.shape[0])\n",
    "\n",
    "plt.plot(range(1,n_epochs+1), mse_SGD_train, label=\"mse_SGD_train\")\n",
    "plt.plot(range(1,n_epochs+1), mse_SGD_test, label=\"mse_SGD_test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
